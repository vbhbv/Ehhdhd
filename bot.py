import os
import asyncio
import tempfile
import aiofiles
import random
import re
from aiohttp import ClientSession
from bs4 import BeautifulSoup
from telegram import InlineKeyboardButton, InlineKeyboardMarkup, Update
from telegram.ext import ApplicationBuilder, CommandHandler, CallbackQueryHandler, ContextTypes
from urllib.parse import urljoin

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¨ÙˆØª ---
BOT_TOKEN = os.getenv("BOT_TOKEN")
USER_AGENT = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
USER_AGENT_HEADER = {'User-Agent': USER_AGENT}
MIN_PDF_SIZE_BYTES = 50 * 1024
TEMP_LINKS_KEY = "current_search_links"

# --- 50 Ù…ÙƒØªØ¨Ø© Ø¹Ø±Ø¨ÙŠØ© ---
LIBRARY_SITES = [
    "https://ketabpedia.com", "https://sahm-book.com", "https://foulabook.com", "https://mktbtypdf.com",
    "https://kotobati.com", "https://masaha.org", "https://almeshkat.com", "https://noor-book.com",
    "https://almeshkat.net", "https://arab-pdf.com", "https://kitab4u.com", "https://kutub.info",
    "https://library4all.com", "https://al-fikr.com", "https://almaktaba.org", "https://books-world.net",
    "https://al-islah.org", "https://pdf4arab.com", "https://freearabebooks.com", "https://arbookshop.com",
    "https://almeshkatbooks.com", "https://arpdf.net", "https://pdfbooksarab.com", "https://al-maktabah.com",
    "https://arabebooksite.com", "https://kutub-pdf.com", "https://ebook-4arab.com", "https://almeshkat-ebooks.com",
    "https://kutubarabia.net", "https://pdf-ebooksarab.com", "https://alkitabonline.com", "https://arbooks.net",
    "https://freearabicbooks.com", "https://arabicpdfbooks.net", "https://kutubpdf.com", "https://arabicbookarchive.com",
    "https://kutub-ebooks.com", "https://pdfkitab.com", "https://alkitabpdf.com", "https://arabicbooklibrary.com",
    "https://almeshkatpdf.com", "https://kutub-arab.com", "https://pdfarabicbooks.com", "https://ebooks4arab.com",
    "https://kutubonline.net", "https://pdfbooks4arab.com", "https://arabiclibrary.org", "https://kutubfree.com",
    "https://ebooks-arab.com", "https://kitabpdf.net"
]

# --- Ø¯Ø§Ù„Ø© Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…Ø¨Ø§Ø´Ø± ÙÙŠ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª ---
async def search_libraries(query: str):
    headers = USER_AGENT_HEADER.copy()
    results = []

    async with ClientSession() as session:
        for site in LIBRARY_SITES:
            try:
                # Ù†Ø¨Ø­Ø« ÙÙŠ ØµÙØ­Ø© Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø§Ù„Ù…ÙˆÙ‚Ø¹
                search_url = f"{site}/search?q={query.replace(' ', '+')}"
                async with session.get(search_url, headers=headers, timeout=15) as resp:
                    if resp.status != 200:
                        continue
                    html = await resp.text()
                    soup = BeautifulSoup(html, "html.parser")

                    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø±ÙˆØ§Ø¨Ø· PDF Ø£Ùˆ Ø²Ø± ØªØ­Ù…ÙŠÙ„
                    for a in soup.find_all("a", href=True):
                        href = urljoin(site, a['href'])
                        title = a.get_text(strip=True) or "ÙƒØªØ§Ø¨ Ø¨Ø¯ÙˆÙ† Ø¹Ù†ÙˆØ§Ù†"

                        # Ù‚Ø¨ÙˆÙ„ Ø£ÙŠ PDF Ù…Ø¨Ø§Ø´Ø± Ø£Ùˆ ØµÙØ­Ø© ØªØ­Ù…ÙŠÙ„
                        if href.lower().endswith(".pdf") or "download" in href.lower():
                            results.append({
                                "title": title,
                                "link": href,
                                "source": site
                            })
            except Exception:
                continue

    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù…ÙƒØ±Ø±Ø©
    unique_links = {}
    for item in results:
        unique_links[item['link']] = item
    return list(unique_links.values())[:10]  # Ø£ÙØ¶Ù„ 10 Ø±ÙˆØ§Ø¨Ø·

# --- Ø¯Ø§Ù„Ø© ØªØ­Ù…ÙŠÙ„ PDF ÙˆØ¥Ø±Ø³Ø§Ù„Ù‡ ---
async def download_and_send_pdf(context, chat_id, source, title="book.pdf"):
    tmp_dir = tempfile.gettempdir()
    safe_title = re.sub(r"[\\/*?\"<>|]", "_", title)[:50]
    file_path = os.path.join(tmp_dir, f"{safe_title}.pdf")

    async with ClientSession() as session:
        try:
            async with session.get(source, headers=USER_AGENT_HEADER, timeout=30) as resp:
                if resp.status != 200:
                    await context.bot.send_message(chat_id=chat_id, text=f"âš ï¸ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù: {resp.status}")
                    return
                content = await resp.read()
                if len(content) < MIN_PDF_SIZE_BYTES:
                    await context.bot.send_message(chat_id=chat_id, text="âš ï¸ Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù ØµØºÙŠØ± Ø¬Ø¯Ù‹Ø§.")
                    return
                async with aiofiles.open(file_path, "wb") as f:
                    await f.write(content)
        except Exception as e:
            await context.bot.send_message(chat_id=chat_id, text=f"âš ï¸ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù: {e}")
            return

    # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù…Ù„Ù ÙˆØ­Ø°ÙÙ‡ Ø¨Ø¹Ø¯ Ø§Ù„Ø¥Ø±Ø³Ø§Ù„
    try:
        with open(file_path, "rb") as f:
            await context.bot.send_document(chat_id=chat_id, document=f)
        await context.bot.send_message(chat_id=chat_id, text="âœ… ØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ÙƒØªØ§Ø¨ Ø¨Ù†Ø¬Ø§Ø­.")
    except Exception as e:
        await context.bot.send_message(chat_id=chat_id, text=f"âš ï¸ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¥Ø±Ø³Ø§Ù„: {e}")
    finally:
        if os.path.exists(file_path):
            os.remove(file_path)

# --- Telegram handlers ---
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("ğŸ“š Ø¨ÙˆØª Ø§Ù„ÙƒØªØ¨ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¬Ø§Ù‡Ø²! Ø§Ø³ØªØ®Ø¯Ù… /search Ù…ØªØ¨ÙˆØ¹Ù‹Ø§ Ø¨Ø§Ø³Ù… Ø§Ù„ÙƒØªØ§Ø¨ Ø£Ùˆ Ø§Ù„Ù…Ø¤Ù„Ù.")

async def search_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = " ".join(context.args).strip()
    if not query:
        await update.message.reply_text("Ø§Ø³ØªØ®Ø¯Ù…: /search Ø§Ø³Ù… Ø§Ù„ÙƒØªØ§Ø¨ Ø£Ùˆ Ø§Ù„Ù…Ø¤Ù„Ù")
        return
    msg = await update.message.reply_text(f"ğŸ” Ø£Ø¨Ø­Ø« Ø¹Ù† '{query}' ÙÙŠ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©...")
    try:
        results = await search_libraries(query)
        if not results:
            await msg.edit_text("âŒ Ù„Ù… Ø£Ø¬Ø¯ Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.")
            return

        buttons = []
        text_lines = []
        context.user_data[TEMP_LINKS_KEY] = [item["link"] for item in results]
        for i, item in enumerate(results):
            title = item["title"][:100]
            text_lines.append(f"{i+1}. {title} ({item['source']})")
            buttons.append([InlineKeyboardButton(f"ğŸ“¥ ØªØ­Ù…ÙŠÙ„ {i+1}", callback_data=f"dl|{i}")])
        await msg.edit_text("\n".join(text_lines), reply_markup=InlineKeyboardMarkup(buttons))
    except Exception as e:
        await msg.edit_text(f"âš ï¸ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¨Ø­Ø«: {e}")

async def callback_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    data = query.data
    if data.startswith("dl|"):
        index = int(data.split("|")[1])
        link = context.user_data[TEMP_LINKS_KEY][index]
        await query.edit_message_text("â³ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙƒØªØ§Ø¨...")
        await download_and_send_pdf(context, query.message.chat_id, link, title=f"book_{index+1}.pdf")

def main():
    if not BOT_TOKEN:
        raise ValueError("BOT_TOKEN Ù…ÙÙ‚ÙˆØ¯ ÙÙŠ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦ÙŠØ©.")
    app = ApplicationBuilder().token(BOT_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("search", search_cmd))
    app.add_handler(CallbackQueryHandler(callback_handler))
    print("Ø§Ù„Ø¨ÙˆØª Ø¨Ø¯Ø£ Ø§Ù„Ø¹Ù…Ù„.")
    app.run_polling()

if __name__ == "__main__":
    main()
