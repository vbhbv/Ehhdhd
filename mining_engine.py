import joblib
import pandas as pd
import numpy as np
import asyncio
import re
from typing import List, Dict, Any, Optional
# ØªØ£ÙƒØ¯ Ù…Ù† ØªØ«Ø¨ÙŠØª Ù‡Ø°Ù‡ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª ÙÙŠ requirements.txt:
from bs4 import BeautifulSoup 
from playwright.async_api import async_playwright 

# -----------------------------------------------------
#                ÙˆØ­Ø¯Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ (AI Selector)
# -----------------------------------------------------

# ðŸš¨ Ø¯Ø§Ù„Ø© Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ù…ÙŠØ²Ø§Øª Ù„Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ (Inference) - 8 Ù…ÙŠØ²Ø§Øª
def feature_engineer_for_inference(record: dict) -> list:
    """ØªØ³ØªØ®Ø±Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø«Ù…Ø§Ù†ÙŠØ© Ø¨Ù†ÙØ³ Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ø°ÙŠ ØªÙ… Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„ÙŠÙ‡."""
    
    text_content = record.get('text_content', '')
    tag_type = record.get('tag_type', '')
    css_class = record.get('css_class', '')
    href = record.get('href', '')
    css_selector = record.get('css_selector', '')
    is_near_pdf_keyword = record.get('is_near_pdf_keyword', 0)
    feat_depth = record.get('feat_depth', 0)
    feat_is_in_main_section = record.get('feat_is_in_main_section', 0)

    features = []
    
    # Ø§Ù„Ù€ 8 Ù…ÙŠØ²Ø§Øª Ø¨Ø§Ù„ØªØ±ØªÙŠØ¨:
    features.append(1.0 if ('ØªØ­Ù…ÙŠÙ„' in text_content or 'download' in text_content.lower()) else 0.0) # 1
    features.append(1.0 if tag_type == 'a' else 0.0) # 2
    features.append(float(len(css_class.split()) if css_class else 0.0)) # 3
    features.append(float(is_near_pdf_keyword)) # 4
    features.append(1.0 if (href and (href.endswith('.pdf') or href.endswith('.zip') or href.endswith('.epub'))) else 0.0) # 5
    features.append(float(css_selector.count('.') + css_selector.count('#') if css_selector else 0.0)) # 6
    features.append(float(feat_depth)) # 7
    features.append(float(feat_is_in_main_section)) # 8
    
    return features


# ðŸš¨ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (AI_SELECTOR_MODEL)
try:
    AI_SELECTOR_MODEL = joblib.load('selector_classifier_model.pkl')
    print("âœ… ÙˆØ­Ø¯Ø© MiningEngine: ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø¨Ù†Ø¬Ø§Ø­.")
except Exception as e:
    AI_SELECTOR_MODEL = None
    # ØªØ£ÙƒØ¯ Ù…Ù† Ø±ÙØ¹ Ù…Ù„Ù selector_classifier_model.pkl Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹!
    print(f"âŒ ÙˆØ­Ø¯Ø© MiningEngine: ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ. Ø§Ù„Ø®Ø·Ø£: {e}")

# -----------------------------------------------------
#                   ÙƒÙ„Ø§Ø³ MiningEngine
# -----------------------------------------------------

class MiningEngine:
    
    @staticmethod
    async def get_pdf_link_and_headers(page: Any) -> Optional[Dict[str, Any]]:
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        if AI_SELECTOR_MODEL is None:
            return None 

        html_content = await page.content()
        soup = BeautifulSoup(html_content, 'html.parser')
        
        best_selector = None
        max_probability = 0.0
        candidates = []

        # 1. Ø¬Ù…Ø¹ Ø§Ù„Ù…Ø±Ø´Ø­ÙŠÙ† ÙˆØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù‡ÙŠÙƒÙ„ÙŠØ©
        for tag in soup.find_all(['a', 'button']):
            href = tag.get('href')
            if not href or href.startswith('#'):
                continue

            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¹Ù…Ù‚ (feat_depth) ÙˆØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ (feat_is_in_main_section)
            parent_count = 0
            current_tag = tag
            while current_tag.parent is not None and current_tag.parent.name not in ['[document]', 'html']:
                parent_count += 1
                current_tag = current_tag.parent
            is_in_main = 1 if tag.find_parent(['main', 'article']) else 0
            
            record = {
                "text_content": tag.get_text().strip(),
                "tag_type": tag.name,
                "css_class": tag.get('class', [''])[0],
                "css_selector": f"{tag.name}[href='{href}']", 
                "href": href,
                "feat_depth": parent_count,
                "feat_is_in_main_section": is_in_main,
                "is_near_pdf_keyword": 1 if 'pdf' in tag.get_text().lower() else 0
            }
            candidates.append(record)

        if not candidates:
            return None

        # 2. ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø±Ø´Ø­ÙŠÙ† Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
        
        for record in candidates:
            features = feature_engineer_for_inference(record)
            # Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ù„Ù„ØªØµÙ†ÙŠÙ 1 (Ø§Ù„Ù‡Ø¯Ù)
            probability = AI_SELECTOR_MODEL.predict_proba(np.array([features]))[0][1] 
            
            if probability > max_probability:
                max_probability = probability
                best_selector = record['css_selector']
        
        CONFIDENCE_THRESHOLD = 0.70 
        
        # 3. Ø§Ù„Ù‚Ø±Ø§Ø± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
        if max_probability < CONFIDENCE_THRESHOLD:
            print(f"âš ï¸ ØªÙ†Ø¨ÙŠÙ‡: Ø£ÙØ¶Ù„ Ø§Ø­ØªÙ…Ø§Ù„ ({max_probability:.4f}) Ø£Ù‚Ù„ Ù…Ù† 70%.")
            return None
        
        print(f"âœ… ØªÙ… Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…Ø­Ø¯Ø¯: {best_selector} ({max_probability:.4f})")
        
        # ... (Ù‡Ù†Ø§ ÙŠÙ…ÙƒÙ†Ùƒ ÙˆØ¶Ø¹ Ù…Ù†Ø·Ù‚ Ø§Ù„Ù†Ù‚Ø± ÙˆÙ…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø´Ø¨ÙƒØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… best_selector) ...
        return {"selector": best_selector, "confidence": max_probability}


# -----------------------------------------------------
#                   Ù…Ù†Ø·Ù‚ Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ (Main Execution)
# -----------------------------------------------------

async def run_mining_task(url: str):
    """Ø¯Ø§Ù„Ø© Ù„ÙØªØ­ Ø§Ù„Ù…ØªØµÙØ­ ÙˆØªÙ†ÙÙŠØ° Ù…Ù‡Ù…Ø© Ø§Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ."""
    print(f"\n--- Ø¨Ø¯Ø¡ Ù…Ù‡Ù…Ø© Ø§Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ Ù„Ù„Ø±Ø§Ø¨Ø·: {url} ---")
    
    async with async_playwright() as p:
        # ÙŠØ±Ø¬Ù‰ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…ØªØµÙØ­ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„Ù†Ø´Ø± (Chromium Ù‡Ùˆ Ø§Ù„Ø£ÙƒØ«Ø± Ø´ÙŠÙˆØ¹Ø§Ù‹)
        browser = await p.chromium.launch() 
        page = await browser.new_page()
        
        # Ø§Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ø¥Ù„Ù‰ Ø§Ù„Ø±Ø§Ø¨Ø·
        try:
            await page.goto(url, timeout=60000)
            print("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙØ­Ø©.")
        except Exception as e:
            print(f"âŒ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙØ­Ø©: {e}")
            await browser.close()
            return

        # ØªÙ†ÙÙŠØ° Ù…Ù†Ø·Ù‚ Ø§Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ
        result = await MiningEngine.get_pdf_link_and_headers(page)
        
        if result:
            print("\nðŸŒŸ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©:")
            print(f"Ø§Ù„Ù…ÙØ­Ø¯Ù‘ÙØ¯ Ø§Ù„Ø£ÙØ¶Ù„: {result['selector']}")
            print(f"Ø¯Ø±Ø¬Ø© Ø§Ù„Ø«Ù‚Ø©: {result['confidence']:.4f}")
            # ... (Ù‡Ù†Ø§ ÙŠÙ…ÙƒÙ† Ø£Ù† ØªØ¶Ø¹ Ù…Ù†Ø·Ù‚ Ø§Ù„Ù†Ù‚Ø± Ø§Ù„ÙØ¹Ù„ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Playwright) ...
        else:
            print("\nâŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø­Ø¯Ø¯ ØªØ­Ù…ÙŠÙ„ Ù…ÙˆØ«ÙˆÙ‚.")

        await browser.close()
        print("--- Ø§Ù†ØªÙ‡Øª Ø§Ù„Ù…Ù‡Ù…Ø© ---")

# ðŸš¨ ØªØ¹Ø¯ÙŠÙ„ Ù‡Ø°Ø§ Ø§Ù„Ø¬Ø²Ø¡ Ù„Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ 
if __name__ == "__main__":
    # Ø¶Ø¹ Ù‡Ù†Ø§ Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ø°ÙŠ ØªØ±ÙŠØ¯ Ø§Ø®ØªØ¨Ø§Ø±Ù‡ Ø£Ùˆ Ø§Ø³ØªØ®Ù„Ø§Øµ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù†Ù‡
    TEST_URL = "https://books-library.website/" 
    try:
        asyncio.run(run_mining_task(TEST_URL))
    except KeyboardInterrupt:
        print("ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ ÙŠØ¯ÙˆÙŠØ§Ù‹.")
