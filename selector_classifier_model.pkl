{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"18a0wkRQ2gE_02PW4KCdmtxCsCrjk6q2m","timestamp":1762106693711}],"authorship_tag":"ABX9TyM29r2+9GSindby4aFpq3qw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["\n","# --- Ø§Ù„Ø®Ù„ÙŠØ© 1: Ø§Ù„ØªÙˆÙ„ÙŠØ¯ØŒ Ø§Ù„Ù‡Ù†Ø¯Ø³Ø©ØŒ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ØŒ ÙˆØ§Ù„Ø­ÙØ¸ (Ø­Ù„ Ù†Ù‡Ø§Ø¦ÙŠ) ---\n","\n","import json\n","import random\n","import pandas as pd\n","import numpy as np\n","import joblib\n","from typing import List, Dict, Any\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report, accuracy_score\n","import os\n","\n","print(\"--- ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ù…ÙˆØ­Ø¯Ø©: ØªÙˆÙ„ÙŠØ¯ ÙˆØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (8 Ù…ÙŠØ²Ø§Øª) ğŸš€ ---\")\n","\n","# --- 1. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠØ© ÙˆØ§Ù„ØªÙˆÙ„ÙŠØ¯ (Ù†ÙØ³ Ø§Ù„Ù…Ù†Ø·Ù‚) ---\n","NUM_RECORDS = 500\n","# ... (ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù‚ÙˆØ§Ø¦Ù… Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©: TAG_TYPES, DOWNLOAD_WORDS, Ø¥Ù„Ø® ÙƒÙ…Ø§ ÙÙŠ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø³Ø§Ø¨Ù‚) ...\n","\n","def generate_record(is_target: bool) -> Dict[str, Any]:\n","    # ... (Ù†ÙØ³ Ù…Ù†Ø·Ù‚ Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ù„Ù€ 8 Ù…ÙŠØ²Ø§Øª) ...\n","    # (Ù‡Ù†Ø§ ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø­Ù‚ÙˆÙ„: text_content, tag_type, css_class, css_selector, href, is_near_pdf_keyword, is_target, feat_depth, feat_is_in_main_section)\n","    # Ù…Ù„Ø§Ø­Ø¸Ø©: Ø³Ù†Ø¨Ù‚ÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ù€ 8 Ù…ÙŠØ²Ø§Øª ÙƒÙ…Ø§ Ù‡ÙŠ ÙÙŠ Ø§Ù„Ø­ÙØ¸ Ù„Ø¶Ù…Ø§Ù† Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ø£ÙŠ Ø´ÙŠØ¡ Ø¥Ø¶Ø§ÙÙŠ.\n","\n","    # [ØªØ®ÙŠÙ„ Ø£Ù† Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„ÙƒØ§Ù…Ù„ Ù„Ù„Ø¯Ø§Ù„Ø© generate_record Ù…ÙˆØ¬ÙˆØ¯ Ù‡Ù†Ø§]\n","\n","    # ÙˆÙ„Ø¶Ù…Ø§Ù† Ø§Ù„Ø¹Ù…Ù„ØŒ Ø³Ù†Ù†Ø³Ø® Ù…Ù†Ø·Ù‚ generate_record Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ù„Ø¶Ù…Ø§Ù† Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ø£Ø®Ø·Ø§Ø¡ Ù…Ø³Ø§ÙØ§Øª Ø¨Ø§Ø¯Ø¦Ø©:\n","    tag_type = random.choice(['a', 'button']) if is_target else random.choice(['a', 'button', 'div', 'span'])\n","    if is_target:\n","        text_content = f\"{random.choice(['ØªØ­Ù…ÙŠÙ„', 'Download'])} {random.choice(['PDF', ''])}\"\n","        css_class = 'btn primary download'\n","        href = f\"/get-book/{random.randint(1000, 9999)}.pdf\"\n","        feat_depth = random.randint(5, 12)\n","        feat_is_in_main_section = 1\n","        is_near_pdf_keyword = 1\n","    else:\n","        text_content = f\"Ù…Ø±Ø§Ø¬Ø¹Ø© {random.choice(['Ø§Ù„ÙƒØªØ§Ø¨', 'Ø§Ù„Ø±ÙˆØ§ÙŠØ©'])}\"\n","        css_class = 'link review secondary'\n","        href = f\"/page/{random.randint(1, 50)}\"\n","        feat_depth = random.randint(3, 15)\n","        feat_is_in_main_section = 0\n","        is_near_pdf_keyword = 0\n","\n","    css_selector = f\"{tag_type}#{'id' + str(random.randint(1, 100))}\"\n","\n","    return {\n","        \"text_content\": text_content.strip(),\n","        \"tag_type\": tag_type,\n","        \"css_class\": css_class,\n","        \"css_selector\": css_selector,\n","        \"href\": href,\n","        \"is_near_pdf_keyword\": is_near_pdf_keyword,\n","        \"is_target\": 1 if is_target else 0,\n","        \"feat_depth\": feat_depth,\n","        \"feat_is_in_main_section\": feat_is_in_main_section\n","    }\n","\n","\n","# ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØªØ­Ù…ÙŠÙ„Ù‡Ø§ Ù…Ø¨Ø§Ø´Ø±Ø© Ø¥Ù„Ù‰ DataFrame (df)\n","training_data = [generate_record(random.random() < 0.4) for _ in range(NUM_RECORDS)]\n","df = pd.DataFrame(training_data)\n","df = df.fillna(0) # ØªÙ†Ø¸ÙŠÙ ÙƒØ§Ù…Ù„ Ù„Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©\n","print(f\"âœ… ØªÙ… ØªÙˆÙ„ÙŠØ¯ ÙˆØªØ­Ù…ÙŠÙ„ {len(df)} Ø³Ø¬Ù„ ØªØ¯Ø±ÙŠØ¨ÙŠ Ø¨Ù†Ø¬Ø§Ø­.\")\n","\n","\n","# --- 2. Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ù…ÙŠØ²Ø§Øª (8 Ù…ÙŠØ²Ø§Øª) Ø§Ù„Ù…ÙØµØ­Ù‘ÙØ­Ø© ---\n","\n","def feature_engineer(df_input: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"ØªØ³ØªØ®Ø±Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø¹Ø¯Ø¯ÙŠØ© Ø§Ù„Ù€ 8 ÙÙ‚Ø·.\"\"\"\n","\n","    # 1. feat_has_download_word\n","    df_input['feat_has_download_word'] = df_input['text_content'].str.contains('ØªØ­Ù…ÙŠÙ„|download', case=False, na=False).astype(int)\n","\n","    # 2. feat_is_anchor (<a>)\n","    df_input['feat_is_anchor'] = df_input['tag_type'].apply(lambda x: 1 if x == 'a' else 0)\n","\n","    # 3. feat_class_length (Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª)\n","    df_input['feat_class_length'] = df_input['css_class'].apply(lambda x: len(x.split()) if isinstance(x, str) else 0)\n","\n","    # 4. feat_structural_proximity (Ø§Ù„Ù‚Ø±Ø¨ Ù…Ù† ÙƒÙ„Ù…Ø© PDF/ÙƒØªØ§Ø¨)\n","    df_input['feat_structural_proximity'] = df_input['is_near_pdf_keyword']\n","\n","    # 5. feat_is_file_link (.pdf, .zip, .epub)\n","    df_input['feat_is_file_link'] = df_input['href'].str.endswith(('.pdf', '.zip', '.epub'), na=False).astype(int)\n","\n","    # 6. feat_selector_complexity (Ø¹Ø¯Ø¯ Ø¹Ù„Ø§Ù…Ø§Øª # Ø£Ùˆ .)\n","    df_input['feat_selector_complexity'] = df_input['css_selector'].apply(lambda x: x.count('.') + x.count('#') if isinstance(x, str) else 0)\n","\n","    # 7. feat_depth_v2 (Ø§Ù„Ø¹Ù…Ù‚ Ø§Ù„Ù‡ÙŠÙƒÙ„ÙŠ)\n","    df_input['feat_depth_v2'] = df_input['feat_depth']\n","\n","    # 8. feat_is_in_main_section_v2 (Ù‡Ù„ Ù‡Ùˆ ÙÙŠ Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ)\n","    df_input['feat_is_in_main_section_v2'] = df_input['feat_is_in_main_section']\n","\n","    # ğŸš¨ Ø§Ù„ØªØµØ­ÙŠØ­: Ù†Ø®ØªØ§Ø± Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù€ 8 ÙˆÙ…ÙŠØ²Ù‡ Ø§Ù„Ù‡Ø¯Ù ÙÙ‚Ø· (Ù†Ø¶Ù…Ù† Ø¹Ø¯Ù… Ø³Ø­Ø¨ Ø£ÙŠ Ø£Ø¹Ù…Ø¯Ø© Ø¥Ø¶Ø§ÙÙŠØ© Ù‚Ø¯ÙŠÙ…Ø©)\n","    # ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ø§Ù„Ù†ØªÙŠØ¬Ø© 9 Ø£Ø¹Ù…Ø¯Ø© (8 Ù…ÙŠØ²Ø§Øª + Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù‡Ø¯Ù)\n","    final_cols = ['feat_has_download_word', 'feat_is_anchor', 'feat_class_length', 'feat_structural_proximity',\n","                  'feat_is_file_link', 'feat_selector_complexity', 'feat_depth_v2', 'feat_is_in_main_section_v2', 'is_target']\n","\n","    return df_input[final_cols] # Ù†Ø¹ÙˆØ¯ Ø¨Ù€ 9 Ø£Ø¹Ù…Ø¯Ø© ÙÙ‚Ø·\n","\n","# ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù‡Ù†Ø¯Ø³Ø© ÙˆØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n","features_df = feature_engineer(df.copy())\n","print(f\"âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ {features_df.shape[1] - 1} Ù…ÙŠØ²Ø§Øª Ø¹Ø¯Ø¯ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­.\")\n","\n","X = features_df.drop('is_target', axis=1)\n","y = features_df['is_target']\n","\n","# ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (ÙŠÙØ¹Ø±Ù‘ÙÙ X_train Ùˆ y_train)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","print(f\"âœ… Ù†Ø¬Ø§Ø­ ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª. Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ {X_train.shape[1]} Ù…ÙŠØ²Ø§Øª.\")\n","\n","\n","# --- 3. Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„Ø­ÙØ¸ ---\n","\n","model = RandomForestClassifier(n_estimators=100, random_state=42)\n","print(\"\\nğŸ› ï¸ Ø¨Ø¯Ø¡ ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Random Forest Ø¹Ù„Ù‰ 8 Ù…ÙŠØ²Ø§Øª...\")\n","model.fit(X_train, y_train)\n","print(\"âœ… Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªØ¯Ø±ÙŠØ¨.\")\n","\n","# 4. Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…Ù„Ù Ø¨Ù€ 8 Ù…ÙŠØ²Ø§Øª)\n","MODEL_FILENAME = 'selector_classifier_model.pkl'\n","joblib.dump(model, MODEL_FILENAME)\n","\n","# 5. Ø§Ø®ØªØ¨Ø§Ø± Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­ÙÙˆØ¸ Ù‡Ùˆ 8 Ù…ÙŠØ²Ø§Øª\n","loaded_model = joblib.load(MODEL_FILENAME)\n","\n","# ğŸš¨ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ: ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø¹Ø¯Ø¯ Ø§Ù„Ù…ÙŠØ²Ø§Øª ÙÙŠ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ 8\n","if loaded_model.n_features_in_ == 8:\n","    print(f\"\\nğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­. Ø¹Ø¯Ø¯ Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­ÙÙˆØ¸: 8.\")\n","    print(\"--- âœ… Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø´Ø§Ù…Ù„Ø© Ø§ÙƒØªÙ…Ù„Øª Ø¨Ù†Ø¬Ø§Ø­. Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¬Ø§Ù‡Ø² Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ. ---\")\n","else:\n","    print(f\"\\nâŒ ÙØ´Ù„ ÙÙŠ Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ù…ÙŠØ²Ø§Øª! Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­ÙÙˆØ¸ Ù„Ø¯ÙŠÙ‡ {loaded_model.n_features_in_} Ù…ÙŠØ²Ø©.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lQUWrd0otsF6","executionInfo":{"status":"ok","timestamp":1762106200768,"user_tz":-180,"elapsed":979,"user":{"displayName":"Kdjd Jdjdh","userId":"00828850567043768780"}},"outputId":"efa84363-61f7-4809-ba9f-cb11dd58a3b3"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["--- ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ù…ÙˆØ­Ø¯Ø©: ØªÙˆÙ„ÙŠØ¯ ÙˆØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (8 Ù…ÙŠØ²Ø§Øª) ğŸš€ ---\n","âœ… ØªÙ… ØªÙˆÙ„ÙŠØ¯ ÙˆØªØ­Ù…ÙŠÙ„ 500 Ø³Ø¬Ù„ ØªØ¯Ø±ÙŠØ¨ÙŠ Ø¨Ù†Ø¬Ø§Ø­.\n","âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ 8 Ù…ÙŠØ²Ø§Øª Ø¹Ø¯Ø¯ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­.\n","âœ… Ù†Ø¬Ø§Ø­ ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª. Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ 8 Ù…ÙŠØ²Ø§Øª.\n","\n","ğŸ› ï¸ Ø¨Ø¯Ø¡ ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Random Forest Ø¹Ù„Ù‰ 8 Ù…ÙŠØ²Ø§Øª...\n","âœ… Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªØ¯Ø±ÙŠØ¨.\n","\n","ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­. Ø¹Ø¯Ø¯ Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­ÙÙˆØ¸: 8.\n","--- âœ… Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø´Ø§Ù…Ù„Ø© Ø§ÙƒØªÙ…Ù„Øª Ø¨Ù†Ø¬Ø§Ø­. Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¬Ø§Ù‡Ø² Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ. ---\n"]}]},{"cell_type":"code","source":["\n","# --- Ø§Ù„Ø®Ù„ÙŠØ© 2: Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø¨Ù€ 8 Ù…ÙŠØ²Ø§Øª ÙˆØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ---\n","\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","\n","# 1. ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© (Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ÙƒÙˆØ¯ Ù…Ù†ÙØµÙ„Ø§Ù‹)\n","# Ù‡Ø°Ø§ ÙŠØ¶Ù…Ù† Ø£Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù†ØµÙŠØ© ÙˆØ§Ù„Ù‡ÙŠÙƒÙ„ÙŠØ© Ø¬Ø§Ù‡Ø²Ø© Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©\n","df = df.fillna({'text_content': '', 'css_class': '', 'href': ''})\n","df = df.fillna(0) # ØªØ¹ÙˆÙŠØ¶ Ø£ÙŠ NaN Ù…ØªØ¨Ù‚ÙŠØ© Ø¨Ø§Ù„ØµÙØ±\n","\n","def feature_engineer(df_input: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"ØªØ³ØªØ®Ø±Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø¹Ø¯Ø¯ÙŠØ© Ø§Ù„Ù€ 8 Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù„Ù„ØªØ¯Ø±ÙŠØ¨.\"\"\"\n","\n","    # 1. feat_has_download_word (Ù†ØµÙŠ)\n","    df_input['feat_has_download_word'] = df_input['text_content'].str.contains('ØªØ­Ù…ÙŠÙ„|download', case=False, na=False).astype(int)\n","\n","    # 2. feat_is_anchor (Ù‡ÙŠÙƒÙ„ÙŠ)\n","    df_input['feat_is_anchor'] = df_input['tag_type'].apply(lambda x: 1 if x == 'a' else 0)\n","\n","    # 3. feat_class_length (Ù‡ÙŠÙƒÙ„ÙŠ)\n","    df_input['feat_class_length'] = df_input['css_class'].apply(lambda x: len(x.split()) if isinstance(x, str) else 0)\n","\n","    # 4. feat_structural_proximity (Ù‡ÙŠÙƒÙ„ÙŠØŒ Ù…Ù† Ø§Ù„ØªÙˆÙ„ÙŠØ¯)\n","    df_input['feat_structural_proximity'] = df_input['is_near_pdf_keyword']\n","\n","    # 5. feat_is_file_link (Ù†ØµÙŠ/Ø±Ø§Ø¨Ø·)\n","    df_input['feat_is_file_link'] = df_input['href'].str.endswith(('.pdf', '.zip', '.epub'), na=False).astype(int)\n","\n","    # 6. feat_selector_complexity (Ù‡ÙŠÙƒÙ„ÙŠ)\n","    df_input['feat_selector_complexity'] = df_input['css_selector'].apply(lambda x: x.count('.') + x.count('#') if isinstance(x, str) else 0)\n","\n","    # 7. feat_depth_v2 (Ø§Ù„Ø¹Ù…Ù‚ Ø§Ù„Ù‡ÙŠÙƒÙ„ÙŠØŒ Ù…Ù† Ø§Ù„ØªÙˆÙ„ÙŠØ¯)\n","    df_input['feat_depth_v2'] = df_input['feat_depth']\n","\n","    # 8. feat_is_in_main_section_v2 (Ù‡Ù„ Ù‡Ùˆ ÙÙŠ Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØŒ Ù…Ù† Ø§Ù„ØªÙˆÙ„ÙŠØ¯)\n","    df_input['feat_is_in_main_section_v2'] = df_input['feat_is_in_main_section']\n","\n","    # ğŸš¨ ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©: Ù†Ø®ØªØ§Ø± Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù€ 8 ÙˆÙ…ÙŠØ²Ù‡ Ø§Ù„Ù‡Ø¯Ù ÙÙ‚Ø·\n","    final_cols = ['feat_has_download_word', 'feat_is_anchor', 'feat_class_length', 'feat_structural_proximity',\n","                  'feat_is_file_link', 'feat_selector_complexity', 'feat_depth_v2', 'feat_is_in_main_section_v2', 'is_target']\n","\n","    return df_input[final_cols] # Ù†Ø¹ÙˆØ¯ Ø¨Ù€ 9 Ø£Ø¹Ù…Ø¯Ø© ÙÙ‚Ø· (8 Ù…ÙŠØ²Ø§Øª + Ø§Ù„Ù‡Ø¯Ù)\n","\n","# 2. ØªØ·Ø¨ÙŠÙ‚ Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ù…ÙŠØ²Ø§Øª ÙˆÙØµÙ„ Ø§Ù„Ù‡Ø¯Ù\n","features_df = feature_engineer(df.copy())\n","print(f\"âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ {features_df.shape[1] - 1} Ù…ÙŠØ²Ø§Øª Ø¹Ø¯Ø¯ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­.\")\n","\n","# 3. ÙØµÙ„ Ø§Ù„Ù…ÙŠØ²Ø§Øª (X) Ø¹Ù† Ø§Ù„Ù‡Ø¯Ù (Y)\n","X = features_df.drop('is_target', axis=1)\n","y = features_df['is_target']\n","\n","# 4. ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„Ø§Ø®ØªØ¨Ø§Ø± (Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª X_train, y_train, X_test, y_test)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","print(f\"\\nâœ… Ù†Ø¬Ø§Ø­ ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª. Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ {X_train.shape[1]} Ù…ÙŠØ²Ø§Øª.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZEL0_Arwt2Cz","executionInfo":{"status":"ok","timestamp":1762106241913,"user_tz":-180,"elapsed":72,"user":{"displayName":"Kdjd Jdjdh","userId":"00828850567043768780"}},"outputId":"b48d4a70-dd1c-4486-c7f7-71f20da72a53"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ 8 Ù…ÙŠØ²Ø§Øª Ø¹Ø¯Ø¯ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­.\n","\n","âœ… Ù†Ø¬Ø§Ø­ ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª. Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ 8 Ù…ÙŠØ²Ø§Øª.\n"]}]},{"cell_type":"code","source":["\n","# --- Ø§Ù„Ø®Ù„ÙŠØ© 3: ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ­ÙØ¸Ù‡ ---\n","\n","import joblib\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report, accuracy_score\n","\n","# 1. ØªÙ‡ÙŠØ¦Ø© Ù†Ù…ÙˆØ°Ø¬ Random Forest\n","# Ù†Ø³ØªØ®Ø¯Ù… Ø¹Ø¯Ø¯ Ø£Ø´Ø¬Ø§Ø± (n_estimators) Ù„Ø¶Ù…Ø§Ù† Ù†Ù…ÙˆØ°Ø¬ Ù‚ÙˆÙŠ.\n","model = RandomForestClassifier(n_estimators=100, random_state=42)\n","\n","# 2. ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬\n","print(\"ğŸ› ï¸ Ø¨Ø¯Ø¡ ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Random Forest Ø¹Ù„Ù‰ 8 Ù…ÙŠØ²Ø§Øª...\")\n","# ÙŠØ³ØªØ®Ø¯Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª X_train Ùˆ y_train Ø§Ù„ØªÙŠ ØªÙ… ØªØ¹Ø±ÙŠÙÙ‡Ø§ ÙÙŠ Ø§Ù„Ø®Ù„ÙŠØ© 2\n","try:\n","    model.fit(X_train, y_train)\n","    print(\"âœ… Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¨Ù†Ø¬Ø§Ø­.\")\n","except NameError:\n","    print(\"âŒ Ø®Ø·Ø£: Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª X_train Ø£Ùˆ y_train ØºÙŠØ± Ù…ÙØ¹Ø±Ù‘ÙÙØ©. ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ØªÙ†ÙÙŠØ° Ø§Ù„Ø®Ù„ÙŠØ© 2 Ø£ÙˆÙ„Ø§Ù‹.\")\n","    raise\n","except ValueError as e:\n","    print(f\"âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {e}\")\n","    raise\n","\n","\n","# 3. Ø§Ù„ØªÙ†Ø¨Ø¤ ÙˆØ§Ù„ØªÙ‚ÙŠÙŠÙ…\n","y_pred = model.predict(X_test)\n","print(\"\\n--- ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡ ---\")\n","\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Ø¯Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (Accuracy): {accuracy:.4f}\")\n","\n","# ØªÙ‚Ø±ÙŠØ± ØªØµÙ†ÙŠÙ Ù…ÙØµÙ„ (Precision, Recall, F1-Score)\n","print(\"ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØµÙ†ÙŠÙ:\\n\", classification_report(y_test, y_pred, target_names=['Not Target (0)', 'Target (1)']))\n","\n","# 4. Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…Ù„Ù Ø¨Ù€ 8 Ù…ÙŠØ²Ø§Øª)\n","MODEL_FILENAME = 'selector_classifier_model.pkl'\n","joblib.dump(model, MODEL_FILENAME)\n","\n","# 5. Ø§Ø®ØªØ¨Ø§Ø± Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­ÙÙˆØ¸ Ù‡Ùˆ 8 Ù…ÙŠØ²Ø§Øª\n","loaded_model = joblib.load(MODEL_FILENAME)\n","if loaded_model.n_features_in_ == 8:\n","    print(f\"\\nğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­ Ø¨Ø§Ø³Ù…: {MODEL_FILENAME}. Ø¹Ø¯Ø¯ Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­ÙÙˆØ¸: 8.\")\n","else:\n","    # ÙŠØ¬Ø¨ Ø£Ù„Ø§ ÙŠØ­Ø¯Ø« Ù‡Ø°Ø§ Ø§Ù„Ø®Ø·Ø£ Ø¨Ø¹Ø¯ ØªØµØ­ÙŠØ­ Ø§Ù„Ø®Ù„ÙŠØ© 2\n","    print(f\"\\nâŒ ØªØ­Ø°ÙŠØ±: Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­ÙÙˆØ¸ Ù„Ø¯ÙŠÙ‡ {loaded_model.n_features_in_} Ù…ÙŠØ²Ø©. ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† 8.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vAtZRp0Qt3de","executionInfo":{"status":"ok","timestamp":1762106264115,"user_tz":-180,"elapsed":561,"user":{"displayName":"Kdjd Jdjdh","userId":"00828850567043768780"}},"outputId":"65e57436-30c4-422d-a0d7-6d26a7c6f3a7"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ› ï¸ Ø¨Ø¯Ø¡ ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Random Forest Ø¹Ù„Ù‰ 8 Ù…ÙŠØ²Ø§Øª...\n","âœ… Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¨Ù†Ø¬Ø§Ø­.\n","\n","--- ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡ ---\n","Ø¯Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (Accuracy): 1.0000\n","ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØµÙ†ÙŠÙ:\n","                 precision    recall  f1-score   support\n","\n","Not Target (0)       1.00      1.00      1.00        61\n","    Target (1)       1.00      1.00      1.00        39\n","\n","      accuracy                           1.00       100\n","     macro avg       1.00      1.00      1.00       100\n","  weighted avg       1.00      1.00      1.00       100\n","\n","\n","ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­ Ø¨Ø§Ø³Ù…: selector_classifier_model.pkl. Ø¹Ø¯Ø¯ Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­ÙÙˆØ¸: 8.\n"]}]},{"cell_type":"code","source":["\n","# --- Ø§Ù„Ø®Ù„ÙŠØ© 4: ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªÙ†Ø¨Ø¤ ---\n","\n","import joblib\n","import pandas as pd\n","import numpy as np\n","\n","MODEL_FILENAME = 'selector_classifier_model.pkl'\n","\n","# 1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­ÙÙˆØ¸\n","try:\n","    ai_model = joblib.load(MODEL_FILENAME)\n","    print(f\"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­ Ù…Ù†: {MODEL_FILENAME}\")\n","except Exception as e:\n","    print(f\"âŒ Ø®Ø·Ø£: Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ({MODEL_FILENAME}).\")\n","    raise\n","\n","# 2. Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ø®ØªØ¨Ø§Ø± Ø¨Ø³ÙŠØ·Ø© (8 Ù…ÙŠØ²Ø§Øª)\n","# ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø¨Ù†ÙØ³ Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ø°ÙŠ ØªÙ… ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„ÙŠÙ‡:\n","# 1. feat_has_download_word\n","# 2. feat_is_anchor\n","# 3. feat_class_length\n","# 4. feat_structural_proximity\n","# 5. feat_is_file_link\n","# 6. feat_selector_complexity\n","# 7. feat_depth_v2 (Ø§Ù„Ø¹Ù…Ù‚)\n","# 8. feat_is_in_main_section_v2 (ÙÙŠ Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ)\n","\n","print(f\"âœ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠØªÙˆÙ‚Ø¹ {ai_model.n_features_in_} Ù…ÙŠØ²Ø§Øª ÙÙŠ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„.\")\n","\n","# Ù…Ø«Ø§Ù„ 1: Ø²Ø± ØªØ­Ù…ÙŠÙ„ Ø­Ù‚ÙŠÙ‚ÙŠ (Ù…Ø«Ø§Ù„ÙŠ) -> ØªÙˆÙ‚Ø¹: 1 (Ù‡Ø¯Ù)\n","# Ø§Ù„Ù…ÙŠØ²Ø§Øª: [ØªØ­Ù…ÙŠÙ„ØŸ, Ø±Ø§Ø¨Ø·ØŸ, Ø·ÙˆÙ„ ÙØ¦Ø©, Ù‚Ø±Ø¨ØŸ, Ù…Ù„ÙØŸ, ØªØ¹Ù‚ÙŠØ¯, Ø¹Ù…Ù‚, Ø±Ø¦ÙŠØ³ÙŠØŸ]\n","features_real_download = [1.0, 1.0, 3.0, 1.0, 1.0, 3.0, 8.0, 1.0]\n","\n","# Ù…Ø«Ø§Ù„ 2: Ø±Ø§Ø¨Ø· Ù…Ø±Ø§Ø¬Ø¹Ø© Ø¹Ø§Ø¯ÙŠ (ØºÙŠØ± Ù‡Ø¯Ù)\n","features_review_link = [0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 5.0, 0.0]\n","\n","# Ù…Ø«Ø§Ù„ 3: Ø²Ø± Ù…Ø´Ø§Ø±ÙƒØ© Ù…Ø¹Ù‚Ø¯ (ØºÙŠØ± Ù‡Ø¯Ù)\n","features_share_button = [0.0, 0.0, 4.0, 0.0, 0.0, 4.0, 10.0, 1.0]\n","\n","\n","# 3. Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬\n","new_data = pd.DataFrame([features_real_download, features_review_link, features_share_button])\n","\n","# Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ø£Ù† ÙŠÙƒÙˆÙ† Ù‡Ùˆ Ø§Ù„Ù‡Ø¯Ù (Ø§Ù„ØªØµÙ†ÙŠÙ 1)\n","# Ù†Ø³ØªØ®Ø¯Ù… .values Ù„Ù„ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ù…ØµÙÙˆÙØ© numpy Ù„Ø¶Ù…Ø§Ù† Ø§Ù„ØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬\n","probabilities = ai_model.predict_proba(new_data.values)[:, 1]\n","\n","# 4. Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬\n","print(\"\\n--- Ù†ØªØ§Ø¦Ø¬ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ---\")\n","test_cases = [\"Ø²Ø± ØªØ­Ù…ÙŠÙ„ Ø­Ù‚ÙŠÙ‚ÙŠ (Ù…Ø«Ø§Ù„ÙŠ)\", \"Ø±Ø§Ø¨Ø· Ù…Ø±Ø§Ø¬Ø¹Ø© Ø¹Ø§Ø¯ÙŠ\", \"Ø²Ø± Ù…Ø´Ø§Ø±ÙƒØ© Ù…Ø¹Ù‚Ø¯\"]\n","\n","for i, prob in enumerate(probabilities):\n","    prediction = \"Ù‡Ø¯Ù (ØªØ­Ù…ÙŠÙ„)\" if prob >= 0.75 else \"ØºÙŠØ± Ù‡Ø¯Ù\"\n","\n","    print(f\"Ø§Ù„Ø­Ø§Ù„Ø© {i+1}: {test_cases[i]}\")\n","    print(f\"   Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ø£Ù† ÙŠÙƒÙˆÙ† Ù‡Ø¯ÙØ§Ù‹: {prob:.4f}\")\n","    print(f\"   Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ù…ÙØ³ØªÙ†ØªÙØ¬: {prediction}\\n\")\n","\n","print(\"Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¬Ø§Ù‡Ø² Ø§Ù„Ø¢Ù† Ù„Ù„Ø¯Ù…Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ ÙÙŠ Ø§Ù„ÙƒÙˆØ¯ V14.0.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZO-yraU9uBm6","executionInfo":{"status":"ok","timestamp":1762106288148,"user_tz":-180,"elapsed":51,"user":{"displayName":"Kdjd Jdjdh","userId":"00828850567043768780"}},"outputId":"e94040e1-b05d-4639-812b-d68a3202ccdc"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­ Ù…Ù†: selector_classifier_model.pkl\n","âœ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠØªÙˆÙ‚Ø¹ 8 Ù…ÙŠØ²Ø§Øª ÙÙŠ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„.\n","\n","--- Ù†ØªØ§Ø¦Ø¬ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ---\n","Ø§Ù„Ø­Ø§Ù„Ø© 1: Ø²Ø± ØªØ­Ù…ÙŠÙ„ Ø­Ù‚ÙŠÙ‚ÙŠ (Ù…Ø«Ø§Ù„ÙŠ)\n","   Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ø£Ù† ÙŠÙƒÙˆÙ† Ù‡Ø¯ÙØ§Ù‹: 1.0000\n","   Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ù…ÙØ³ØªÙ†ØªÙØ¬: Ù‡Ø¯Ù (ØªØ­Ù…ÙŠÙ„)\n","\n","Ø§Ù„Ø­Ø§Ù„Ø© 2: Ø±Ø§Ø¨Ø· Ù…Ø±Ø§Ø¬Ø¹Ø© Ø¹Ø§Ø¯ÙŠ\n","   Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ø£Ù† ÙŠÙƒÙˆÙ† Ù‡Ø¯ÙØ§Ù‹: 0.0000\n","   Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ù…ÙØ³ØªÙ†ØªÙØ¬: ØºÙŠØ± Ù‡Ø¯Ù\n","\n","Ø§Ù„Ø­Ø§Ù„Ø© 3: Ø²Ø± Ù…Ø´Ø§Ø±ÙƒØ© Ù…Ø¹Ù‚Ø¯\n","   Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ø£Ù† ÙŠÙƒÙˆÙ† Ù‡Ø¯ÙØ§Ù‹: 0.2600\n","   Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ù…ÙØ³ØªÙ†ØªÙØ¬: ØºÙŠØ± Ù‡Ø¯Ù\n","\n","Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¬Ø§Ù‡Ø² Ø§Ù„Ø¢Ù† Ù„Ù„Ø¯Ù…Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ ÙÙŠ Ø§Ù„ÙƒÙˆØ¯ V14.0.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n","  warnings.warn(\n"]}]}]}
